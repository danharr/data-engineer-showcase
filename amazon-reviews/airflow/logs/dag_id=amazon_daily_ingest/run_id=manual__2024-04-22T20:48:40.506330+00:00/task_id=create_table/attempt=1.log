[2024-04-22T20:48:42.562+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-04-22T20:48:42.581+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: amazon_daily_ingest.create_table manual__2024-04-22T20:48:40.506330+00:00 [queued]>
[2024-04-22T20:48:42.584+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: amazon_daily_ingest.create_table manual__2024-04-22T20:48:40.506330+00:00 [queued]>
[2024-04-22T20:48:42.584+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 1
[2024-04-22T20:48:42.592+0000] {taskinstance.py:2327} INFO - Executing <Task(SnowflakeOperator): create_table> on 2024-04-22 20:48:40.506330+00:00
[2024-04-22T20:48:42.601+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1329) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-04-22T20:48:42.602+0000] {standard_task_runner.py:63} INFO - Started process 1333 to run task
[2024-04-22T20:48:42.605+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'amazon_daily_ingest', 'create_table', 'manual__2024-04-22T20:48:40.506330+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/amazon/dag.py', '--cfg-path', '/tmp/tmppvp1p7kz']
[2024-04-22T20:48:42.605+0000] {standard_task_runner.py:91} INFO - Job 33: Subtask create_table
[2024-04-22T20:48:42.659+0000] {task_command.py:426} INFO - Running <TaskInstance: amazon_daily_ingest.create_table manual__2024-04-22T20:48:40.506330+00:00 [running]> on host 21d660d07eb5
[2024-04-22T20:48:42.716+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='amazon_daily_ingest' AIRFLOW_CTX_TASK_ID='create_table' AIRFLOW_CTX_EXECUTION_DATE='2024-04-22T20:48:40.506330+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-04-22T20:48:40.506330+00:00'
[2024-04-22T20:48:42.719+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-04-22T20:48:42.720+0000] {sql.py:276} INFO - Executing: CREATE OR REPLACE TABLE AMAZON.RAW.daily_data_s3
                    (reviewerID varchar,
                     asin varchar,
                     overall integer,
                     reviewerName varchar,
                     reviewText varchar,
                     summary varchar,
                     unixReviewTime string);
[2024-04-22T20:48:42.729+0000] {base.py:84} INFO - Using connection ID 'snowflake_trial' for task execution.
[2024-04-22T20:48:42.745+0000] {base.py:84} INFO - Using connection ID 'snowflake_trial' for task execution.
[2024-04-22T20:48:42.745+0000] {connection.py:386} INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.12.2, Platform: Linux-6.6.16-linuxkit-aarch64-with-glibc2.36
[2024-04-22T20:48:42.746+0000] {connection.py:1211} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-04-22T20:48:43.074+0000] {cursor.py:1032} INFO - query: [ALTER SESSION SET autocommit=False]
[2024-04-22T20:48:43.193+0000] {cursor.py:1045} INFO - query execution done
[2024-04-22T20:48:43.199+0000] {cursor.py:1205} INFO - Number of results in first chunk: 1
[2024-04-22T20:48:43.200+0000] {sql.py:457} INFO - Running statement: CREATE OR REPLACE TABLE AMAZON.RAW.daily_data_s3
                    (reviewerID varchar,
                     asin varchar,
                     overall integer,
                     reviewerName varchar,
                     reviewText varchar,
                     summary varchar,
                     unixReviewTime string);, parameters: None
[2024-04-22T20:48:43.200+0000] {cursor.py:1032} INFO - query: [CREATE OR REPLACE TABLE AMAZON.RAW.daily_data_s3 (reviewerID varchar, asin varch...]
[2024-04-22T20:48:43.351+0000] {cursor.py:1045} INFO - query execution done
[2024-04-22T20:48:43.356+0000] {cursor.py:1205} INFO - Number of results in first chunk: 1
[2024-04-22T20:48:43.365+0000] {sql.py:466} INFO - Rows affected: 1
[2024-04-22T20:48:43.377+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/providers/snowflake/hooks/snowflake.py:393: AirflowProviderDeprecationWarning: Call to deprecated method _make_common_data_structure. (The `_make_serializable` method is deprecated and support will be removed in a future version of the common.sql provider. Please update the DbApiHook's provider to a version based on common.sql >= 1.9.1.)
  result = self._make_common_data_structure(handler(cur))  # type: ignore[attr-defined]

[2024-04-22T20:48:43.381+0000] {snowflake.py:402} INFO - Rows affected: 1
[2024-04-22T20:48:43.385+0000] {snowflake.py:403} INFO - Snowflake query id: 01b3d8c0-0000-df07-0001-980e00014062
[2024-04-22T20:48:43.393+0000] {cursor.py:1032} INFO - query: [COMMIT]
[2024-04-22T20:48:43.481+0000] {cursor.py:1045} INFO - query execution done
[2024-04-22T20:48:43.502+0000] {cursor.py:1205} INFO - Number of results in first chunk: 1
[2024-04-22T20:48:43.507+0000] {connection.py:734} INFO - closed
[2024-04-22T20:48:43.544+0000] {connection.py:740} INFO - No async queries seem to be running, deleting session
[2024-04-22T20:48:43.763+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-04-22T20:48:44.337+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=amazon_daily_ingest, task_id=create_table, execution_date=20240422T204840, start_date=20240422T204842, end_date=20240422T204844
[2024-04-22T20:48:44.851+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-04-22T20:48:44.999+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/models/baseoperator.py:1296: AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
  result = cls.__new__(cls)

[2024-04-22T20:48:45.047+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-04-22T20:48:45.052+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
