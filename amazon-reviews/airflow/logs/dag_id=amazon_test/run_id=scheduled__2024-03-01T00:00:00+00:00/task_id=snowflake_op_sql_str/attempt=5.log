[2024-04-22T15:03:40.704+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-04-22T15:03:40.716+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: amazon_test.snowflake_op_sql_str scheduled__2024-03-01T00:00:00+00:00 [queued]>
[2024-04-22T15:03:40.720+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: amazon_test.snowflake_op_sql_str scheduled__2024-03-01T00:00:00+00:00 [queued]>
[2024-04-22T15:03:40.720+0000] {taskinstance.py:2303} INFO - Starting attempt 5 of 5
[2024-04-22T15:03:40.725+0000] {taskinstance.py:2327} INFO - Executing <Task(SnowflakeOperator): snowflake_op_sql_str> on 2024-03-01 00:00:00+00:00
[2024-04-22T15:03:40.730+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=409) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-04-22T15:03:40.731+0000] {standard_task_runner.py:63} INFO - Started process 411 to run task
[2024-04-22T15:03:40.732+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'amazon_test', 'snowflake_op_sql_str', 'scheduled__2024-03-01T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/amazon/dag.py', '--cfg-path', '/tmp/tmpb1l8en27']
[2024-04-22T15:03:40.733+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask snowflake_op_sql_str
[2024-04-22T15:03:40.754+0000] {task_command.py:426} INFO - Running <TaskInstance: amazon_test.snowflake_op_sql_str scheduled__2024-03-01T00:00:00+00:00 [running]> on host 21d660d07eb5
[2024-04-22T15:03:40.788+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='amazon_test' AIRFLOW_CTX_TASK_ID='snowflake_op_sql_str' AIRFLOW_CTX_EXECUTION_DATE='2024-03-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='5' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-01T00:00:00+00:00'
[2024-04-22T15:03:40.789+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-04-22T15:03:40.789+0000] {sql.py:276} INFO - Executing: CREATE OR REPLACE TRANSIENT TABLE sample_table (name VARCHAR(250), id INT);
[2024-04-22T15:03:40.794+0000] {base.py:84} INFO - Using connection ID 'snowflake_trial' for task execution.
[2024-04-22T15:03:40.803+0000] {base.py:84} INFO - Using connection ID 'snowflake_trial' for task execution.
[2024-04-22T15:03:40.804+0000] {connection.py:386} INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.12.2, Platform: Linux-6.6.16-linuxkit-aarch64-with-glibc2.36
[2024-04-22T15:03:40.805+0000] {connection.py:1211} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-04-22T15:03:40.838+0000] {connectionpool.py:824} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<snowflake.connector.vendored.urllib3.connection.HTTPSConnection object at 0xffff98bbdac0>: Failed to establish a new connection: [Errno -2] Name or service not known')': //jg26601.eu-west-2.aws.snowflakecomputing.com.snowflakecomputing.com:443/session/v1/login-request?request_id=1adee253-031e-495f-898d-14aa64f4e891&databaseName=AMAZON&schemaName=RAW&warehouse=COMPUTE_WH&roleName=ACCOUNTADMIN
[2024-04-22T15:03:41.867+0000] {connectionpool.py:824} WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<snowflake.connector.vendored.urllib3.connection.HTTPSConnection object at 0xffff98791820>: Failed to establish a new connection: [Errno -2] Name or service not known')': //jg26601.eu-west-2.aws.snowflakecomputing.com.snowflakecomputing.com:443/session/v1/login-request?request_id=d6c38ef7-b30a-4a40-b1dc-47d66abc27a0&databaseName=AMAZON&schemaName=RAW&warehouse=COMPUTE_WH&roleName=ACCOUNTADMIN
[2024-04-22T15:03:41.874+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-04-22T15:03:41.874+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/util/connection.py", line 79, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
snowflake.connector.vendored.urllib3.exceptions.NewConnectionError: <snowflake.connector.vendored.urllib3.connection.HTTPSConnection object at 0xffff98858980>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 827, in urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
snowflake.connector.vendored.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jg26601.eu-west-2.aws.snowflakecomputing.com.snowflakecomputing.com:443/session/v1/login-request?request_id=1adee253-031e-495f-898d-14aa64f4e891&databaseName=AMAZON&schemaName=RAW&warehouse=COMPUTE_WH&roleName=ACCOUNTADMIN (Caused by NewConnectionError('<snowflake.connector.vendored.urllib3.connection.HTTPSConnection object at 0xffff98858980>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1078, in _request_exec
    raw_ret = session.request(
              ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/vendored/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
snowflake.connector.vendored.requests.exceptions.ConnectionError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jg26601.eu-west-2.aws.snowflakecomputing.com.snowflakecomputing.com:443/session/v1/login-request?request_id=1adee253-031e-495f-898d-14aa64f4e891&databaseName=AMAZON&schemaName=RAW&warehouse=COMPUTE_WH&roleName=ACCOUNTADMIN (Caused by NewConnectionError('<snowflake.connector.vendored.urllib3.connection.HTTPSConnection object at 0xffff98858980>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1345, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 734, in _post_request
    ret = self.fetch(
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 843, in fetch
    ret = self._request_exec_wrapper(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 979, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 884, in _request_exec_wrapper
    return_object = self._request_exec(
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/network.py", line 1172, in _request_exec
    raise OperationalError(
snowflake.connector.errors.OperationalError: 251011: 251011: ConnectionTimeout occurred during login. Will be handled by authenticator

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 384, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 278, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/__init__.py", line 54, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 429, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 719, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1045, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1317, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1389, in _authenticate
    raise auth_op from e
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/connection.py", line 1366, in _authenticate
    auth_instance.handle_timeout(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/auth/by_plugin.py", line 212, in handle_timeout
    raise error
snowflake.connector.errors.OperationalError: 250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting
[2024-04-22T15:03:41.887+0000] {taskinstance.py:1205} INFO - Marking task as FAILED. dag_id=amazon_test, task_id=snowflake_op_sql_str, execution_date=20240301T000000, start_date=20240422T150340, end_date=20240422T150341
[2024-04-22T15:03:41.894+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 7 for task snowflake_op_sql_str (250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting; 411)
[2024-04-22T15:03:41.933+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-04-22T15:03:41.941+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/models/baseoperator.py:1296: AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
  result = cls.__new__(cls)

[2024-04-22T15:03:41.948+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-22T15:03:41.950+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
